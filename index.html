<meta charset="utf-8">
                    **RealSynth Simulacron**
          **Ground Truth Image Synthesis and Simulation**

RealSynth Simulacron is a source code customization of the Unreal Engine 4 (UE4) and provides the following main features:
 * Image Segmentation
 * Mesh, Instance, and Material based Labeling

The main use of Simulacron is Ground Truth Image Synthesis and Simulation.

This documentation expects the user to know the basics of how to operate the UE4 Editor. Otherwise please see the various tutorials of the [Unreal Engine Youtube Channel](https://www.youtube.com/channel/UCBobmJyzsJ6Ll7UbfhI4iwQ).

Ground Truth Rendering
===============================================================

Renders pixel accurate labels for each mesh, instance, and material.

Ground Truth View Mode
---------------------------------------------------------------

![The Ground Truth Rendering can be previewed in the Editor](images/ground_truth_preview_editor.jpg)

To enable the Ground Truth View Mode when running without the editor execute the following console command:
``` 
viewmode groundtruth
```
To get back to the default rendering mode enter the following command to the console:
``` 
viewmode lit
```

Render Image Segmentation in real-time
---------------------------------------------------------------

![Real-time scene captures including Image Segmentation can be achieved by placing SceneCapture2D Actors.](images/scene_capture_2d.jpg)

This functionality can be used for closed-loop systems such as verification of a computer vision model.

Render Image Segmentation to disk
---------------------------------------------------------------


![Cinematic Sequence Rendering is used to render segmented images to disk. Once a sequence is set up it should be rendered with the following settings to output the Segmented Images along with the final image rendering to the Ground Truth Capture Output Path.](images/sequence_output_settings.png)

See Output Path Subsection for more details.

This functionality can be used to create a large segmented dataset of images for training of a computer vision model.

Labeling Plugin
---------------------------------------------------------------

![To configue Labels and access Labeling options the Labeling Plugin needs to be activated first.](images/labeling_plugin.png)

Labeling Editor
---------------------------------------------------------------

![Changing labels of whole object classes using the Labeling Editor works as follows: Open the Labeling Editor Mode and select an object you want to change its label of. Enter an expression that also maps to similar objects in that object class and select a label from the drop down menu.](https://www.youtube.com/watch?v=Y_YLS6iFEFs width="680px" height="390px")

The Labeling Editor maps regular expressions to object instances in the level. Each expression can be assigned to a predefined label from the provided KITTI label file. Any changes to the label mapping is automatically saved.

![Existing label mappings can be replaced by adding a new mapping. Each new mapping is prioritized over previously created mappings even if they would match the same instance identifiers.](images/labeling_editor.png)

Settings
---------------------------------------------------------------

![The Labeling Plugin can be configured through the Plugin Settings functionality of the UE4 Editor.](images/labeling_settings.png)

### Label Path
The Label Path is either absolute or relative to the project root directory. A file named "_label_colors.txt" is expected to exist in this directory. It is a KITTI label file. See the [example](_label_colors.txt) of how it should look like.

### Output Path

This path points to the directory where to export the segmented image data. It's either absolute or relative to the project root directory.
False colored images are exported along the segmented annotations. Please use the appropriate Final Image Renderings of the Cinematic Sequence Rendering instead when combining the annotations with synthetic images.

### Use Instance Segmentation

Two different Ground Truth render modes are supported. You can select between Segmentation by Semantic Class and Segmentation by Semantic Class and Instance (Instance Segmentation).

The latter means that each object can be uniquely identified while in the former mode it cannot be distinguished between objects of the same class that overlap in the image. Instance Segmentation can be used to extract annotations like bounding boxes in image space and Learn Energy Landscapes of object classes. Semantic Class Segmentation is usually used for deep learning of image segmentation and is the default segmentation mode.

<!-- Markdeep: -->

<style>em.asterisk { font-style: normal; font-weight: bold; }</style>
<script src="markdeep.min.js"></script>
<script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?"></script>
<script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
